{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from inforetlib.data import *\r\n",
    "from inforetlib.synonyms import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "ld = LoadData()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading topics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "topicn,query = ld.load_topics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading Corpus"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "corpus = ld.load_corpus()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading query results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "qtopicn,idn,label = ld.load_query_results()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "for each query, we pass to the ir engine, which scans the corpus and returns query results. We then compare these query results against the query results data.\r\n",
    "\r\n",
    "because of the way the algorithm works, we need to collect synonyms up to num_synonyms \r\n",
    "\r\n",
    "We also need to normalize the resulting figure to take into account that some words will have many synonyms or big clusters, and some will have few. The scores for the ones with few synonyms, and long documents, will necessarily be lower, but that doesn't necessarily mean they are less relevant. Thus there ought to be a normalization factor which accounts for the number of synonyms/size of cluster and also the length of the document.\r\n",
    "\r\n",
    "We also need to have a maximum number of synonyms/clustered selected words as a parameter."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "syn = Synonyms()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "syn.get('intelligence',stem=False)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['acumen',\n",
       " 'agility',\n",
       " 'brilliance',\n",
       " 'intellect',\n",
       " 'judgment',\n",
       " 'perception',\n",
       " 'quickness',\n",
       " 'savvy',\n",
       " 'sense',\n",
       " 'skill',\n",
       " 'subtlety',\n",
       " 'understanding',\n",
       " 'wit',\n",
       " 'IQ',\n",
       " 'acuity',\n",
       " 'alertness',\n",
       " 'aptitude',\n",
       " 'brainpower',\n",
       " 'brains',\n",
       " 'brightness',\n",
       " 'capacity',\n",
       " 'cleverness',\n",
       " 'comprehension',\n",
       " 'coruscation',\n",
       " 'discernment',\n",
       " 'luminosity',\n",
       " 'mentality',\n",
       " 'mind',\n",
       " 'penetration',\n",
       " 'perspicacity',\n",
       " 'precocity',\n",
       " 'quotient',\n",
       " 'reason',\n",
       " 'sagacity',\n",
       " 'smarts',\n",
       " 'trenchancy']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class SynonymRetrieval:\r\n",
    "    def __init__(self):\r\n",
    "        self.__syn = Synonyms()\r\n",
    "\r\n",
    "    \r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "ex = corpus[0]['text']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def preprocess_document(string):\r\n",
    "    string = string.replace('-',' ')\r\n",
    "    string = ''.join([i for i in string if (i.isalpha()) or (i == ' ')])\r\n",
    "    string = string.lower()\r\n",
    "    string = nltk.word_tokenize(string)\r\n",
    "    string = list(set(string))\r\n",
    "    # remove stopwords\r\n",
    "    string = [word for word in string if not word in nltk.corpus.stopwords.words()]\r\n",
    "    ps = nltk.stem.PorterStemmer()\r\n",
    "    string = [ps.stem(w) for w in string]\r\n",
    "    # stem\r\n",
    "    return set(string)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def preprocess_query(query):\r\n",
    "    # need to get synonyms\r\n",
    "\r\n",
    "    # need to remove stopwords from query\r\n",
    "\r\n",
    "    # need to tokenize and stem synonyms and query\r\n",
    "\r\n",
    "    # need to return each as a set"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get set intersection. Discount factor determines the divisor for the jaccard score of the either synonyms, or clustered words"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "ex = preprocess(ex)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'chang', 'coronaviru', 'respons', 'weather'}"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b1f09a33527022494cbc1a3254192479adc88b8f7fdce239975774d86eaf2091"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}